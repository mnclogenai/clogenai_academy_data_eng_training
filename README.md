# ClogenAI Academy - Data Pipeline Engineering Training

This repository contains training materials, sample code, and session notes for the ClogenAI Academy Data Pipeline Engineering Training program.

## Repository Structure

```
DataPipelineEngineering/
├── README.md           # This file
├── pyproject.toml      # Python project configuration
├── poetry.lock         # Dependency lock file
├── week1/             # Session 1: Introduction & Fundamentals
│   └── week1.md
├── week2/             # Session 2: Data Ingestion & Storage
│   ├── week2.md
│   ├── Week2_Ingest_Explore_PySpark.ipynb
│   └── Week2_Ingest_Explore_PySpark.py
├── week3/             # Session 3: Data Cleaning & Transformation
│   ├── week3.md
│   └── Week3_Spark_PySpark_Programming.ipynb
├── week4/             # Session 4: PySpark Transformations & Modeling
│   ├── week4.md
│   ├── week4-extra.md          # Additional code samples
│   └── Week4_PySpark_Transformations_Modeling.ipynb
├── week5/             # Session 5: Data Quality & Validation
│   ├── week5.md
│   ├── week5-extra.md          # Additional code samples
│   └── Week5_Data_Quality_Validations.ipynb
├── code/              # Shared code and utilities
├── datasets/          # Training datasets
└── resources/         # Additional learning materials
```

## Training Program Overview

This comprehensive training program covers modern data pipeline engineering using Apache Spark, Delta Lake, and the Medallion Architecture. Students will learn to build scalable, reliable data pipelines from ingestion to analytics-ready datasets.

### Key Technologies Covered
- **Apache Spark & PySpark** - Distributed data processing
- **Delta Lake** - ACID transactions and data versioning
- **Medallion Architecture** - Bronze, Silver, Gold data layers
- **Databricks** - Unified analytics platform
- **ETL/ELT Patterns** - Modern data transformation approaches
- **Data Quality & Validation** - Great Expectations, Delta constraints, monitoring

### Learning Path
1. **Week 1**: Foundations of data pipeline engineering
2. **Week 2**: Data ingestion strategies and storage patterns
3. **Week 3**: Data cleaning, transformation, and quality management
4. **Week 4**: PySpark transformations, schema evolution, and Gold layer modeling
5. **Week 5**: Data quality dimensions, validation frameworks, and monitoring

## Session Details

### Week 4: PySpark Transformations & Modeling
- **Focus**: Schema evolution, incremental processing, analytical transformations
- **Key Topics**: MERGE operations, window functions, Gold layer design
- **Deliverables**: Customer LTV analysis, revenue metrics, retention analysis

### Week 5: Data Quality & Validation
- **Focus**: Data quality dimensions, validation frameworks, monitoring
- **Key Topics**: Great Expectations, Delta constraints, quality pipelines
- **Deliverables**: Comprehensive data quality framework, automated validation



## Getting Started

1. Clone this repository
2. Review the weekly session notes in order
3. Practice with the provided code examples
4. Complete hands-on exercises using the sample datasets
5. Use the tech guides for comprehensive implementation reference

## Prerequisites
- Basic Python programming knowledge
- Understanding of SQL fundamentals
- Access to Databricks workspace (provided during training)

## Support
For questions or support, contact the ClogenAI Academy training team.