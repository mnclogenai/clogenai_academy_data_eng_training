{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 ‚Äì Data Quality & Validation\n",
    "\n",
    "## Learning Objectives\n",
    "By the end of this session, you will:\n",
    "- üîç Identify data quality dimensions and common issues in datasets\n",
    "- üìã Design validation rules using schema enforcement and rule-based approaches\n",
    "- üéØ Implement Great Expectations Core for declarative validation\n",
    "- üõ°Ô∏è Apply Delta constraints and PySpark validation logic\n",
    "- üìä Set up data quality monitoring and profiling dashboards\n",
    "- ‚úÖ Build robust data quality pipelines with automated validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from delta.tables import DeltaTable\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Week5_DataQuality\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"‚úÖ Spark session initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 1: Data Quality Dimensions & Issue Identification\n",
    "\n",
    "### Create Sample Dataset with Quality Issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample orders data with intentional quality issues\n",
    "sample_data = [\n",
    "    (\"ORD001\", \"CUST001\", 150.50, \"2024-01-15\", \"completed\", \"john@email.com\"),\n",
    "    (\"ORD002\", \"CUST002\", -25.00, \"2024-01-16\", \"pending\", \"jane.doe@company.com\"),  # Negative amount\n",
    "    (\"ORD003\", None, 75.25, \"2024-01-17\", \"cancelled\", \"invalid-email\"),  # Missing customer_id, invalid email\n",
    "    (\"ORD004\", \"CUST003\", 200.00, \"2024-01-18\", \"completed\", \"bob@test.org\"),\n",
    "    (\"ORD004\", \"CUST003\", 200.00, \"2024-01-18\", \"completed\", \"bob@test.org\"),  # Duplicate\n",
    "    (None, \"CUST004\", 99.99, \"2024-01-19\", \"invalid_status\", \"alice@domain.co.uk\"),  # Missing order_id, invalid status\n",
    "    (\"ORD006\", \"CUST005\", None, \"2024-01-20\", \"pending\", \"charlie@email.net\"),  # Missing amount\n",
    "    (\"ORD007\", \"CUST006\", 300.75, None, \"completed\", \"diana@company.com\"),  # Missing date\n",
    "]\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), True),\n",
    "    StructField(\"customer_id\", StringType(), True),\n",
    "    StructField(\"amount\", DoubleType(), True),\n",
    "    StructField(\"order_date\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"email\", StringType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(sample_data, schema)\n",
    "df.show()\n",
    "print(f\"Total records: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Schema inspection\n",
    "print(\"=== SCHEMA INSPECTION ===\")\n",
    "df.printSchema()\n",
    "\n",
    "# 2. Basic statistics\n",
    "print(\"\\n=== BASIC STATISTICS ===\")\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Check for missing values (Completeness)\n",
    "print(\"=== COMPLETENESS CHECK ===\")\n",
    "null_counts = df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_counts.show()\n",
    "\n",
    "# Calculate completeness percentage\n",
    "total_rows = df.count()\n",
    "for column in df.columns:\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    completeness = ((total_rows - null_count) / total_rows) * 100\n",
    "    print(f\"{column}: {completeness:.1f}% complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Check for duplicates (Uniqueness)\n",
    "print(\"=== UNIQUENESS CHECK ===\")\n",
    "duplicate_orders = df.groupBy(\"order_id\").count().filter(\"count > 1\")\n",
    "print(f\"Duplicate order_ids: {duplicate_orders.count()}\")\n",
    "duplicate_orders.show()\n",
    "\n",
    "# Show duplicate records\n",
    "if duplicate_orders.count() > 0:\n",
    "    duplicate_ids = [row.order_id for row in duplicate_orders.collect()]\n",
    "    df.filter(col(\"order_id\").isin(duplicate_ids)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Check for invalid ranges (Validity)\n",
    "print(\"=== VALIDITY CHECK ===\")\n",
    "\n",
    "# Negative amounts\n",
    "negative_amounts = df.filter(col(\"amount\") < 0).count()\n",
    "print(f\"Records with negative amounts: {negative_amounts}\")\n",
    "\n",
    "# Invalid email formats\n",
    "email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "invalid_emails = df.filter(~col(\"email\").rlike(email_pattern)).count()\n",
    "print(f\"Records with invalid email formats: {invalid_emails}\")\n",
    "\n",
    "# Invalid status values\n",
    "valid_statuses = [\"pending\", \"completed\", \"cancelled\"]\n",
    "invalid_status = df.filter(~col(\"status\").isin(valid_statuses)).count()\n",
    "print(f\"Records with invalid status: {invalid_status}\")\n",
    "\n",
    "# Show invalid records\n",
    "print(\"\\nInvalid records:\")\n",
    "df.filter(\n",
    "    (col(\"amount\") < 0) | \n",
    "    (~col(\"email\").rlike(email_pattern)) | \n",
    "    (~col(\"status\").isin(valid_statuses))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Issues Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create quality issues summary\n",
    "quality_issues = [\n",
    "    (\"Missing order_id\", \"Completeness\", df.filter(col(\"order_id\").isNull()).count()),\n",
    "    (\"Missing customer_id\", \"Completeness\", df.filter(col(\"customer_id\").isNull()).count()),\n",
    "    (\"Missing amount\", \"Completeness\", df.filter(col(\"amount\").isNull()).count()),\n",
    "    (\"Missing order_date\", \"Completeness\", df.filter(col(\"order_date\").isNull()).count()),\n",
    "    (\"Duplicate order_ids\", \"Uniqueness\", duplicate_orders.count()),\n",
    "    (\"Negative amounts\", \"Validity\", negative_amounts),\n",
    "    (\"Invalid emails\", \"Validity\", invalid_emails),\n",
    "    (\"Invalid status\", \"Validity\", invalid_status)\n",
    "]\n",
    "\n",
    "quality_df = spark.createDataFrame(quality_issues, [\"Issue\", \"Dimension\", \"Count\"])\n",
    "quality_df.show(truncate=False)\n",
    "\n",
    "print(\"\\nüìä Quality Assessment Complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 2: Validation Approaches & Rule Design\n",
    "\n",
    "### Schema Enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define strict schema with proper types\n",
    "strict_schema = StructType([\n",
    "    StructField(\"order_id\", StringType(), False),  # NOT NULL\n",
    "    StructField(\"customer_id\", StringType(), False),  # NOT NULL\n",
    "    StructField(\"amount\", DoubleType(), False),  # NOT NULL\n",
    "    StructField(\"order_date\", DateType(), False),  # NOT NULL\n",
    "    StructField(\"status\", StringType(), False),  # NOT NULL\n",
    "    StructField(\"email\", StringType(), True)  # NULLABLE\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Strict schema defined\")\n",
    "print(\"Schema will enforce:\")\n",
    "print(\"- order_id: NOT NULL\")\n",
    "print(\"- customer_id: NOT NULL\")\n",
    "print(\"- amount: NOT NULL, DoubleType\")\n",
    "print(\"- order_date: NOT NULL, DateType\")\n",
    "print(\"- status: NOT NULL\")\n",
    "print(\"- email: NULLABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_orders(df):\n",
    "    \"\"\"Apply comprehensive validation rules\"\"\"\n",
    "    \n",
    "    # Define validation conditions\n",
    "    email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "    valid_statuses = [\"pending\", \"completed\", \"cancelled\"]\n",
    "    \n",
    "    return df.withColumn(\"validation_errors\", \n",
    "        when(col(\"order_id\").isNull(), \"Missing order_id\")\n",
    "        .when(col(\"customer_id\").isNull(), \"Missing customer_id\")\n",
    "        .when(col(\"amount\").isNull(), \"Missing amount\")\n",
    "        .when(col(\"amount\") <= 0, \"Invalid amount (must be positive)\")\n",
    "        .when(col(\"order_date\").isNull(), \"Missing order_date\")\n",
    "        .when(~col(\"status\").isin(valid_statuses), \"Invalid status\")\n",
    "        .when(col(\"email\").isNotNull() & ~col(\"email\").rlike(email_pattern), \"Invalid email format\")\n",
    "        .otherwise(\"Valid\")\n",
    "    ).withColumn(\"is_valid\", \n",
    "        when(col(\"validation_errors\") == \"Valid\", True).otherwise(False)\n",
    "    )\n",
    "\n",
    "# Apply validation\n",
    "validated_df = validate_orders(df)\n",
    "validated_df.show(truncate=False)\n",
    "\n",
    "# Summary of validation results\n",
    "validation_summary = validated_df.groupBy(\"validation_errors\").count().orderBy(desc(\"count\"))\n",
    "validation_summary.show(truncate=False)\n",
    "\n",
    "valid_count = validated_df.filter(col(\"is_valid\") == True).count()\n",
    "invalid_count = validated_df.filter(col(\"is_valid\") == False).count()\n",
    "print(f\"\\nüìä Validation Summary:\")\n",
    "print(f\"Valid records: {valid_count}\")\n",
    "print(f\"Invalid records: {invalid_count}\")\n",
    "print(f\"Data quality rate: {(valid_count / df.count()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Validation Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_validation(df):\n",
    "    \"\"\"Apply multiple validation rules with detailed error tracking\"\"\"\n",
    "    \n",
    "    email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "    valid_statuses = [\"pending\", \"completed\", \"cancelled\"]\n",
    "    \n",
    "    return df \\\n",
    "        .withColumn(\"has_order_id\", col(\"order_id\").isNotNull()) \\\n",
    "        .withColumn(\"has_customer_id\", col(\"customer_id\").isNotNull()) \\\n",
    "        .withColumn(\"has_valid_amount\", (col(\"amount\").isNotNull()) & (col(\"amount\") > 0)) \\\n",
    "        .withColumn(\"has_order_date\", col(\"order_date\").isNotNull()) \\\n",
    "        .withColumn(\"has_valid_status\", col(\"status\").isin(valid_statuses)) \\\n",
    "        .withColumn(\"has_valid_email\", \n",
    "            when(col(\"email\").isNull(), True)  # Email is optional\n",
    "            .otherwise(col(\"email\").rlike(email_pattern))\n",
    "        ) \\\n",
    "        .withColumn(\"validation_score\", \n",
    "            col(\"has_order_id\").cast(\"int\") +\n",
    "            col(\"has_customer_id\").cast(\"int\") +\n",
    "            col(\"has_valid_amount\").cast(\"int\") +\n",
    "            col(\"has_order_date\").cast(\"int\") +\n",
    "            col(\"has_valid_status\").cast(\"int\") +\n",
    "            col(\"has_valid_email\").cast(\"int\")\n",
    "        ) \\\n",
    "        .withColumn(\"quality_grade\", \n",
    "            when(col(\"validation_score\") == 6, \"A - Excellent\")\n",
    "            .when(col(\"validation_score\") == 5, \"B - Good\")\n",
    "            .when(col(\"validation_score\") == 4, \"C - Fair\")\n",
    "            .otherwise(\"D - Poor\")\n",
    "        )\n",
    "\n",
    "# Apply comprehensive validation\n",
    "comprehensive_df = comprehensive_validation(df)\n",
    "comprehensive_df.select(\"order_id\", \"validation_score\", \"quality_grade\").show()\n",
    "\n",
    "# Quality grade distribution\n",
    "grade_distribution = comprehensive_df.groupBy(\"quality_grade\").count().orderBy(\"quality_grade\")\n",
    "grade_distribution.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 3: Great Expectations Core Implementation\n",
    "\n",
    "### Install and Setup Great Expectations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: In a real environment, you would install Great Expectations\n",
    "# !pip install great-expectations\n",
    "\n",
    "# For this demo, we'll simulate Great Expectations functionality\n",
    "# with PySpark-based expectations\n",
    "\n",
    "class SimpleExpectations:\n",
    "    \"\"\"Simplified Great Expectations-like functionality\"\"\"\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.expectations = []\n",
    "        self.results = []\n",
    "    \n",
    "    def expect_column_values_to_not_be_null(self, column):\n",
    "        null_count = self.df.filter(col(column).isNull()).count()\n",
    "        success = null_count == 0\n",
    "        self.expectations.append({\n",
    "            'expectation': f'expect_column_values_to_not_be_null({column})',\n",
    "            'success': success,\n",
    "            'details': f'Found {null_count} null values'\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def expect_column_values_to_be_unique(self, column):\n",
    "        total_count = self.df.count()\n",
    "        unique_count = self.df.select(column).distinct().count()\n",
    "        success = total_count == unique_count\n",
    "        self.expectations.append({\n",
    "            'expectation': f'expect_column_values_to_be_unique({column})',\n",
    "            'success': success,\n",
    "            'details': f'Total: {total_count}, Unique: {unique_count}'\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def expect_column_values_to_be_between(self, column, min_value, max_value):\n",
    "        out_of_range = self.df.filter(\n",
    "            (col(column) < min_value) | (col(column) > max_value)\n",
    "        ).count()\n",
    "        success = out_of_range == 0\n",
    "        self.expectations.append({\n",
    "            'expectation': f'expect_column_values_to_be_between({column}, {min_value}, {max_value})',\n",
    "            'success': success,\n",
    "            'details': f'Found {out_of_range} values out of range'\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def expect_column_values_to_be_in_set(self, column, value_set):\n",
    "        invalid_count = self.df.filter(~col(column).isin(value_set)).count()\n",
    "        success = invalid_count == 0\n",
    "        self.expectations.append({\n",
    "            'expectation': f'expect_column_values_to_be_in_set({column}, {value_set})',\n",
    "            'success': success,\n",
    "            'details': f'Found {invalid_count} invalid values'\n",
    "        })\n",
    "        return self\n",
    "    \n",
    "    def validate(self):\n",
    "        all_passed = all(exp['success'] for exp in self.expectations)\n",
    "        return {\n",
    "            'success': all_passed,\n",
    "            'expectations': self.expectations,\n",
    "            'summary': f\"{sum(1 for exp in self.expectations if exp['success'])}/{len(self.expectations)} expectations passed\"\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Simple Expectations class created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Run Expectation Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create expectation suite for orders data\n",
    "expectations = SimpleExpectations(df)\n",
    "\n",
    "# Add expectations\n",
    "expectations \\\n",
    "    .expect_column_values_to_not_be_null(\"order_id\") \\\n",
    "    .expect_column_values_to_not_be_null(\"customer_id\") \\\n",
    "    .expect_column_values_to_be_unique(\"order_id\") \\\n",
    "    .expect_column_values_to_be_between(\"amount\", 0, 10000) \\\n",
    "    .expect_column_values_to_be_in_set(\"status\", [\"pending\", \"completed\", \"cancelled\"])\n",
    "\n",
    "# Run validation\n",
    "results = expectations.validate()\n",
    "\n",
    "print(f\"\\nüìä Expectation Suite Results:\")\n",
    "print(f\"Overall Success: {results['success']}\")\n",
    "print(f\"Summary: {results['summary']}\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "\n",
    "for exp in results['expectations']:\n",
    "    status = \"‚úÖ PASS\" if exp['success'] else \"‚ùå FAIL\"\n",
    "    print(f\"{status} - {exp['expectation']}\")\n",
    "    print(f\"    Details: {exp['details']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data and Re-validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data by removing/fixing issues\n",
    "clean_df = df \\\n",
    "    .filter(col(\"order_id\").isNotNull()) \\\n",
    "    .filter(col(\"customer_id\").isNotNull()) \\\n",
    "    .filter(col(\"amount\").isNotNull() & (col(\"amount\") > 0)) \\\n",
    "    .filter(col(\"status\").isin([\"pending\", \"completed\", \"cancelled\"])) \\\n",
    "    .dropDuplicates([\"order_id\"])\n",
    "\n",
    "print(f\"Original records: {df.count()}\")\n",
    "print(f\"Clean records: {clean_df.count()}\")\n",
    "print(f\"Records removed: {df.count() - clean_df.count()}\")\n",
    "\n",
    "# Re-validate clean data\n",
    "clean_expectations = SimpleExpectations(clean_df)\n",
    "clean_expectations \\\n",
    "    .expect_column_values_to_not_be_null(\"order_id\") \\\n",
    "    .expect_column_values_to_not_be_null(\"customer_id\") \\\n",
    "    .expect_column_values_to_be_unique(\"order_id\") \\\n",
    "    .expect_column_values_to_be_between(\"amount\", 0, 10000) \\\n",
    "    .expect_column_values_to_be_in_set(\"status\", [\"pending\", \"completed\", \"cancelled\"])\n",
    "\n",
    "clean_results = clean_expectations.validate()\n",
    "\n",
    "print(f\"\\nüìä Clean Data Validation Results:\")\n",
    "print(f\"Overall Success: {clean_results['success']}\")\n",
    "print(f\"Summary: {clean_results['summary']}\")\n",
    "\n",
    "if clean_results['success']:\n",
    "    print(\"üéâ All expectations passed on clean data!\")\n",
    "else:\n",
    "    print(\"‚ùå Some expectations still failing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 4: Delta Constraints & PySpark Validation\n",
    "\n",
    "### Create Delta Table with Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Delta table with constraints\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TABLE silver.orders (\n",
    "    order_id STRING NOT NULL,\n",
    "    customer_id STRING NOT NULL,\n",
    "    amount DOUBLE,\n",
    "    order_date STRING NOT NULL,\n",
    "    status STRING,\n",
    "    email STRING,\n",
    "    CONSTRAINT positive_amount CHECK (amount > 0),\n",
    "    CONSTRAINT valid_status CHECK (status IN ('pending', 'completed', 'cancelled'))\n",
    ") USING DELTA\n",
    "\"\"\")\n",
    "\n",
    "print(\"‚úÖ Delta table created with constraints:\")\n",
    "print(\"- order_id: NOT NULL\")\n",
    "print(\"- customer_id: NOT NULL\")\n",
    "print(\"- order_date: NOT NULL\")\n",
    "print(\"- positive_amount: CHECK (amount > 0)\")\n",
    "print(\"- valid_status: CHECK (status IN ('pending', 'completed', 'cancelled'))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Constraint Enforcement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to insert clean data (should succeed)\n",
    "try:\n",
    "    clean_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"silver.orders\")\n",
    "    print(\"‚úÖ Clean data inserted successfully\")\n",
    "    \n",
    "    # Check inserted data\n",
    "    result_count = spark.table(\"silver.orders\").count()\n",
    "    print(f\"Records in table: {result_count}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error inserting clean data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to insert invalid data (should fail)\n",
    "invalid_data = [\n",
    "    (\"ORD999\", \"CUST999\", -100.0, \"2024-01-25\", \"pending\", \"test@email.com\")  # Negative amount\n",
    "]\n",
    "\n",
    "invalid_df = spark.createDataFrame(invalid_data, schema)\n",
    "\n",
    "try:\n",
    "    invalid_df.write.format(\"delta\").mode(\"append\").saveAsTable(\"silver.orders\")\n",
    "    print(\"‚ùå Invalid data was inserted (this shouldn't happen!)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úÖ Constraint enforcement working: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced PySpark Validation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_quality_pipeline(input_df, table_name):\n",
    "    \"\"\"Complete data quality pipeline with validation and cleansing\"\"\"\n",
    "    \n",
    "    print(f\"üîÑ Starting data quality pipeline for {table_name}\")\n",
    "    \n",
    "    # Step 1: Initial assessment\n",
    "    initial_count = input_df.count()\n",
    "    print(f\"üìä Initial record count: {initial_count}\")\n",
    "    \n",
    "    # Step 2: Apply validation rules\n",
    "    validated_df = validate_orders(input_df)\n",
    "    \n",
    "    # Step 3: Separate valid and invalid records\n",
    "    valid_df = validated_df.filter(col(\"is_valid\") == True).drop(\"validation_errors\", \"is_valid\")\n",
    "    invalid_df = validated_df.filter(col(\"is_valid\") == False)\n",
    "    \n",
    "    valid_count = valid_df.count()\n",
    "    invalid_count = invalid_df.count()\n",
    "    \n",
    "    print(f\"‚úÖ Valid records: {valid_count}\")\n",
    "    print(f\"‚ùå Invalid records: {invalid_count}\")\n",
    "    print(f\"üìà Data quality rate: {(valid_count / initial_count) * 100:.1f}%\")\n",
    "    \n",
    "    # Step 4: Remove duplicates\n",
    "    clean_df = valid_df.dropDuplicates([\"order_id\"])\n",
    "    final_count = clean_df.count()\n",
    "    duplicates_removed = valid_count - final_count\n",
    "    \n",
    "    if duplicates_removed > 0:\n",
    "        print(f\"üîÑ Removed {duplicates_removed} duplicate records\")\n",
    "    \n",
    "    # Step 5: Write to Delta table\n",
    "    try:\n",
    "        clean_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "        print(f\"‚úÖ Data successfully written to {table_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error writing to table: {str(e)}\")\n",
    "        return None\n",
    "    \n",
    "    # Step 6: Generate quality report\n",
    "    quality_report = {\n",
    "        'initial_records': initial_count,\n",
    "        'valid_records': valid_count,\n",
    "        'invalid_records': invalid_count,\n",
    "        'duplicates_removed': duplicates_removed,\n",
    "        'final_records': final_count,\n",
    "        'quality_rate': (valid_count / initial_count) * 100,\n",
    "        'retention_rate': (final_count / initial_count) * 100\n",
    "    }\n",
    "    \n",
    "    return quality_report, invalid_df\n",
    "\n",
    "# Run the pipeline\n",
    "quality_report, rejected_records = data_quality_pipeline(df, \"silver.orders\")\n",
    "\n",
    "if quality_report:\n",
    "    print(\"\\nüìã Quality Report:\")\n",
    "    for key, value in quality_report.items():\n",
    "        if 'rate' in key:\n",
    "            print(f\"{key}: {value:.1f}%\")\n",
    "        else:\n",
    "            print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Rejected Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze rejected records\n",
    "if rejected_records.count() > 0:\n",
    "    print(\"üìã Rejected Records Analysis:\")\n",
    "    rejected_records.select(\"order_id\", \"customer_id\", \"amount\", \"status\", \"validation_errors\").show(truncate=False)\n",
    "    \n",
    "    # Group by error type\n",
    "    error_summary = rejected_records.groupBy(\"validation_errors\").count().orderBy(desc(\"count\"))\n",
    "    print(\"\\nüìä Error Type Distribution:\")\n",
    "    error_summary.show(truncate=False)\n",
    "else:\n",
    "    print(\"üéâ No rejected records!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic 5: Data Quality Monitoring & Profiling\n",
    "\n",
    "### Create Quality Metrics Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_quality_metrics(df, table_name):\n",
    "    \"\"\"Calculate comprehensive quality metrics for monitoring\"\"\"\n",
    "    \n",
    "    total_rows = df.count()\n",
    "    \n",
    "    if total_rows == 0:\n",
    "        print(\"‚ö†Ô∏è No data to analyze\")\n",
    "        return None\n",
    "    \n",
    "    # Completeness metrics\n",
    "    completeness_metrics = {}\n",
    "    for column in df.columns:\n",
    "        null_count = df.filter(col(column).isNull()).count()\n",
    "        completeness_metrics[f\"{column}_completeness\"] = ((total_rows - null_count) / total_rows) * 100\n",
    "    \n",
    "    # Uniqueness metrics\n",
    "    unique_order_ids = df.select(\"order_id\").distinct().count()\n",
    "    uniqueness_rate = (unique_order_ids / total_rows) * 100\n",
    "    \n",
    "    # Validity metrics\n",
    "    valid_amounts = df.filter((col(\"amount\").isNotNull()) & (col(\"amount\") > 0)).count()\n",
    "    amount_validity = (valid_amounts / total_rows) * 100\n",
    "    \n",
    "    valid_statuses = df.filter(col(\"status\").isin([\"pending\", \"completed\", \"cancelled\"])).count()\n",
    "    status_validity = (valid_statuses / total_rows) * 100\n",
    "    \n",
    "    # Email format validity (for non-null emails)\n",
    "    email_pattern = r\"^[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}$\"\n",
    "    non_null_emails = df.filter(col(\"email\").isNotNull()).count()\n",
    "    if non_null_emails > 0:\n",
    "        valid_emails = df.filter(col(\"email\").isNotNull() & col(\"email\").rlike(email_pattern)).count()\n",
    "        email_validity = (valid_emails / non_null_emails) * 100\n",
    "    else:\n",
    "        email_validity = 100.0  # No emails to validate\n",
    "    \n",
    "    # Overall quality score\n",
    "    quality_scores = [\n",
    "        completeness_metrics.get('order_id_completeness', 0),\n",
    "        completeness_metrics.get('customer_id_completeness', 0),\n",
    "        uniqueness_rate,\n",
    "        amount_validity,\n",
    "        status_validity,\n",
    "        email_validity\n",
    "    ]\n",
    "    overall_quality = sum(quality_scores) / len(quality_scores)\n",
    "    \n",
    "    metrics = {\n",
    "        'table_name': table_name,\n",
    "        'timestamp': spark.sql(\"SELECT current_timestamp()\").collect()[0][0],\n",
    "        'total_records': total_rows,\n",
    "        'unique_order_ids': unique_order_ids,\n",
    "        'uniqueness_rate': uniqueness_rate,\n",
    "        'amount_validity': amount_validity,\n",
    "        'status_validity': status_validity,\n",
    "        'email_validity': email_validity,\n",
    "        'overall_quality_score': overall_quality,\n",
    "        **completeness_metrics\n",
    "    }\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Calculate metrics for our table\n",
    "current_data = spark.table(\"silver.orders\")\n",
    "metrics = calculate_quality_metrics(current_data, \"silver.orders\")\n",
    "\n",
    "if metrics:\n",
    "    print(\"üìä Data Quality Metrics Dashboard\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Table: {metrics['table_name']}\")\n",
    "    print(f\"Timestamp: {metrics['timestamp']}\")\n",
    "    print(f\"Total Records: {metrics['total_records']}\")\n",
    "    print(f\"\\nüéØ Quality Scores:\")\n",
    "    print(f\"Overall Quality Score: {metrics['overall_quality_score']:.1f}%\")\n",
    "    print(f\"Uniqueness Rate: {metrics['uniqueness_rate']:.1f}%\")\n",
    "    print(f\"Amount Validity: {metrics['amount_validity']:.1f}%\")\n",
    "    print(f\"Status Validity: {metrics['status_validity']:.1f}%\")\n",
    "    print(f\"Email Validity: {metrics['email_validity']:.1f}%\")\n",
    "    print(f\"\\nüìã Completeness Rates:\")\n",
    "    for key, value in metrics.items():\n",
    "        if 'completeness' in key:\n",
    "            column_name = key.replace('_completeness', '')\n",
    "            print(f\"{column_name}: {value:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality Monitoring Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate quality monitoring over time\n",
    "def simulate_quality_monitoring():\n",
    "    \"\"\"Simulate quality metrics over multiple time periods\"\"\"\n",
    "    \n",
    "    # Create sample data with varying quality\n",
    "    monitoring_data = [\n",
    "        (\"2024-01-01\", 1000, 95.5, 98.2, 92.1, 89.3),\n",
    "        (\"2024-01-02\", 1050, 94.8, 97.9, 91.5, 88.7),\n",
    "        (\"2024-01-03\", 980, 96.2, 98.5, 93.2, 90.1),\n",
    "        (\"2024-01-04\", 1100, 93.1, 96.8, 89.4, 87.2),  # Quality dip\n",
    "        (\"2024-01-05\", 1075, 95.9, 98.1, 92.8, 89.9),\n",
    "    ]\n",
    "    \n",
    "    monitoring_schema = StructType([\n",
    "        StructField(\"date\", StringType(), False),\n",
    "        StructField(\"record_count\", IntegerType(), False),\n",
    "        StructField(\"completeness_score\", DoubleType(), False),\n",
    "        StructField(\"uniqueness_score\", DoubleType(), False),\n",
    "        StructField(\"validity_score\", DoubleType(), False),\n",
    "        StructField(\"overall_quality\", DoubleType(), False)\n",
    "    ])\n",
    "    \n",
    "    monitoring_df = spark.createDataFrame(monitoring_data, monitoring_schema)\n",
    "    \n",
    "    print(\"üìà Quality Monitoring Trends:\")\n",
    "    monitoring_df.show()\n",
    "    \n",
    "    # Identify quality issues\n",
    "    quality_threshold = 90.0\n",
    "    alerts = monitoring_df.filter(col(\"overall_quality\") < quality_threshold)\n",
    "    \n",
    "    if alerts.count() > 0:\n",
    "        print(f\"üö® Quality Alerts (below {quality_threshold}%):\")\n",
    "        alerts.show()\n",
    "    else:\n",
    "        print(f\"‚úÖ All periods above quality threshold ({quality_threshold}%)\")\n",
    "    \n",
    "    # Calculate trends\n",
    "    avg_quality = monitoring_df.agg(avg(\"overall_quality\")).collect()[0][0]\n",
    "    min_quality = monitoring_df.agg(min(\"overall_quality\")).collect()[0][0]\n",
    "    max_quality = monitoring_df.agg(max(\"overall_quality\")).collect()[0][0]\n",
    "    \n",
    "    print(f\"\\nüìä Quality Trends Summary:\")\n",
    "    print(f\"Average Quality: {avg_quality:.1f}%\")\n",
    "    print(f\"Best Quality: {max_quality:.1f}%\")\n",
    "    print(f\"Worst Quality: {min_quality:.1f}%\")\n",
    "    print(f\"Quality Range: {max_quality - min_quality:.1f}%\")\n",
    "\n",
    "simulate_quality_monitoring()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Exercise: Complete Data Quality Pipeline\n",
    "\n",
    "### Build End-to-End Quality Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_quality_pipeline(source_df, target_table, quality_threshold=85.0):\n",
    "    \"\"\"Complete end-to-end data quality pipeline\"\"\"\n",
    "    \n",
    "    print(\"üöÄ Starting Complete Data Quality Pipeline\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Step 1: Initial Assessment\n",
    "    print(\"\\nüìä Step 1: Initial Data Assessment\")\n",
    "    initial_count = source_df.count()\n",
    "    print(f\"Initial record count: {initial_count}\")\n",
    "    \n",
    "    # Step 2: Schema Validation\n",
    "    print(\"\\nüèóÔ∏è Step 2: Schema Validation\")\n",
    "    required_columns = [\"order_id\", \"customer_id\", \"amount\", \"order_date\", \"status\"]\n",
    "    missing_columns = [col for col in required_columns if col not in source_df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        print(f\"‚ùå Missing required columns: {missing_columns}\")\n",
    "        return None\n",
    "    else:\n",
    "        print(\"‚úÖ All required columns present\")\n",
    "    \n",
    "    # Step 3: Great Expectations Validation\n",
    "    print(\"\\nüéØ Step 3: Great Expectations Validation\")\n",
    "    expectations = SimpleExpectations(source_df)\n",
    "    expectations \\\n",
    "        .expect_column_values_to_not_be_null(\"order_id\") \\\n",
    "        .expect_column_values_to_not_be_null(\"customer_id\") \\\n",
    "        .expect_column_values_to_be_unique(\"order_id\") \\\n",
    "        .expect_column_values_to_be_between(\"amount\", 0, 10000) \\\n",
    "        .expect_column_values_to_be_in_set(\"status\", [\"pending\", \"completed\", \"cancelled\"])\n",
    "    \n",
    "    ge_results = expectations.validate()\n",
    "    print(f\"Expectations passed: {ge_results['summary']}\")\n",
    "    \n",
    "    # Step 4: Rule-Based Validation\n",
    "    print(\"\\nüìã Step 4: Rule-Based Validation\")\n",
    "    validated_df = validate_orders(source_df)\n",
    "    valid_df = validated_df.filter(col(\"is_valid\") == True).drop(\"validation_errors\", \"is_valid\")\n",
    "    invalid_df = validated_df.filter(col(\"is_valid\") == False)\n",
    "    \n",
    "    valid_count = valid_df.count()\n",
    "    invalid_count = invalid_df.count()\n",
    "    quality_rate = (valid_count / initial_count) * 100\n",
    "    \n",
    "    print(f\"Valid records: {valid_count}\")\n",
    "    print(f\"Invalid records: {invalid_count}\")\n",
    "    print(f\"Quality rate: {quality_rate:.1f}%\")\n",
    "    \n",
    "    # Step 5: Quality Gate\n",
    "    print(f\"\\nüö™ Step 5: Quality Gate (threshold: {quality_threshold}%)\")\n",
    "    if quality_rate < quality_threshold:\n",
    "        print(f\"‚ùå Quality gate failed: {quality_rate:.1f}% < {quality_threshold}%\")\n",
    "        print(\"Pipeline stopped. Data quality too low.\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'quality_rate': quality_rate,\n",
    "            'message': 'Quality gate failed'\n",
    "        }\n",
    "    else:\n",
    "        print(f\"‚úÖ Quality gate passed: {quality_rate:.1f}% >= {quality_threshold}%\")\n",
    "    \n",
    "    # Step 6: Data Cleansing\n",
    "    print(\"\\nüßπ Step 6: Data Cleansing\")\n",
    "    clean_df = valid_df.dropDuplicates([\"order_id\"])\n",
    "    final_count = clean_df.count()\n",
    "    duplicates_removed = valid_count - final_count\n",
    "    \n",
    "    if duplicates_removed > 0:\n",
    "        print(f\"Removed {duplicates_removed} duplicate records\")\n",
    "    print(f\"Final clean record count: {final_count}\")\n",
    "    \n",
    "    # Step 7: Delta Constraints Enforcement\n",
    "    print(\"\\nüõ°Ô∏è Step 7: Delta Constraints Enforcement\")\n",
    "    try:\n",
    "        clean_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(target_table)\n",
    "        print(f\"‚úÖ Data written to {target_table} with constraints enforced\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Constraint violation: {str(e)}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'message': f'Constraint violation: {str(e)}'\n",
    "        }\n",
    "    \n",
    "    # Step 8: Quality Metrics Calculation\n",
    "    print(\"\\nüìä Step 8: Quality Metrics Calculation\")\n",
    "    final_data = spark.table(target_table)\n",
    "    metrics = calculate_quality_metrics(final_data, target_table)\n",
    "    \n",
    "    # Step 9: Final Report\n",
    "    print(\"\\nüìã Step 9: Final Quality Report\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    pipeline_result = {\n",
    "        'success': True,\n",
    "        'initial_records': initial_count,\n",
    "        'valid_records': valid_count,\n",
    "        'invalid_records': invalid_count,\n",
    "        'duplicates_removed': duplicates_removed,\n",
    "        'final_records': final_count,\n",
    "        'quality_rate': quality_rate,\n",
    "        'retention_rate': (final_count / initial_count) * 100,\n",
    "        'overall_quality_score': metrics['overall_quality_score'] if metrics else 0,\n",
    "        'target_table': target_table\n",
    "    }\n",
    "    \n",
    "    for key, value in pipeline_result.items():\n",
    "        if key not in ['success', 'target_table']:\n",
    "            if 'rate' in key or 'score' in key:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value:.1f}%\")\n",
    "            else:\n",
    "                print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    print(\"\\nüéâ Data Quality Pipeline Completed Successfully!\")\n",
    "    return pipeline_result\n",
    "\n",
    "# Run the complete pipeline\n",
    "pipeline_result = complete_quality_pipeline(df, \"silver.orders_final\", quality_threshold=70.0)\n",
    "\n",
    "if pipeline_result and pipeline_result['success']:\n",
    "    print(f\"\\n‚úÖ Pipeline Success! Final table: {pipeline_result['target_table']}\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Pipeline Failed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Reflection\n",
    "\n",
    "### Key Learnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìö Week 5 - Data Quality & Validation Summary\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüîç Data Quality Dimensions Covered:\")\n",
    "print(\"‚úÖ Completeness - Identifying missing values\")\n",
    "print(\"‚úÖ Accuracy - Validating data correctness\")\n",
    "print(\"‚úÖ Validity - Checking formats and ranges\")\n",
    "print(\"‚úÖ Uniqueness - Detecting duplicates\")\n",
    "print(\"‚úÖ Consistency - Ensuring uniform values\")\n",
    "print(\"‚úÖ Timeliness - Data currency validation\")\n",
    "\n",
    "print(\"\\nüìã Validation Approaches Implemented:\")\n",
    "print(\"‚úÖ Schema Enforcement - Type and structure validation\")\n",
    "print(\"‚úÖ Rule-Based Logic - Custom PySpark validation functions\")\n",
    "print(\"‚úÖ Great Expectations - Declarative expectation suites\")\n",
    "print(\"‚úÖ Delta Constraints - Database-level enforcement\")\n",
    "\n",
    "print(\"\\nüõ°Ô∏è Quality Pipeline Components:\")\n",
    "print(\"‚úÖ Data profiling and assessment\")\n",
    "print(\"‚úÖ Multi-layer validation\")\n",
    "print(\"‚úÖ Quality gates and thresholds\")\n",
    "print(\"‚úÖ Data cleansing and deduplication\")\n",
    "print(\"‚úÖ Constraint enforcement\")\n",
    "print(\"‚úÖ Quality monitoring and reporting\")\n",
    "\n",
    "print(\"\\nüìä Monitoring and Alerting:\")\n",
    "print(\"‚úÖ Quality metrics calculation\")\n",
    "print(\"‚úÖ Trend analysis\")\n",
    "print(\"‚úÖ Automated quality reporting\")\n",
    "print(\"‚úÖ Threshold-based alerting\")\n",
    "\n",
    "print(\"\\nüéØ Next Steps:\")\n",
    "print(\"‚Ä¢ Implement real-time quality monitoring\")\n",
    "print(\"‚Ä¢ Set up automated quality alerts\")\n",
    "print(\"‚Ä¢ Create quality dashboards\")\n",
    "print(\"‚Ä¢ Establish data quality SLAs\")\n",
    "print(\"‚Ä¢ Build data lineage tracking\")\n",
    "\n",
    "print(\"\\n‚ú® Congratulations! You've completed Week 5 - Data Quality & Validation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
